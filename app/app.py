{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c03f2f2-357f-4150-a326-595ed1728783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Page config\n",
    "# -------------------------------\n",
    "st.set_page_config(\n",
    "    page_title=\"Early Detection of Cognitive Decline Using Speech\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"ðŸ§  Early Detection of Cognitive Decline Using Speech\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "This app uses **audio-derived features** to predict whether a recording is from a  \n",
    "**dementia** or **non-dementia** speaker.\n",
    "\n",
    "Data: engineered features from speech audio (MFCCs, spectral stats, etc.).  \n",
    "Model: Random Forest classifier using scikit-learn.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load and preprocess data\n",
    "# -------------------------------\n",
    "@st.cache_data\n",
    "def load_data(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Clean label\n",
    "    df[\"label\"] = df[\"label\"].astype(str).str.strip().str.lower()\n",
    "    df[\"label\"] = df[\"label\"].replace({\n",
    "        \"dementia\": \"dementia\",\n",
    "        \"ad\": \"dementia\",\n",
    "        \"alzheimers\": \"dementia\",\n",
    "        \"alzheimer's\": \"dementia\",\n",
    "        \"1\": \"dementia\",\n",
    "        \"non-dementia\": \"non-dementia\",\n",
    "        \"non dementia\": \"non-dementia\",\n",
    "        \"healthy\": \"non-dementia\",\n",
    "        \"control\": \"non-dementia\",\n",
    "        \"hc\": \"non-dementia\",\n",
    "        \"0\": \"non-dementia\"\n",
    "    })\n",
    "\n",
    "    df[\"label_num\"] = df[\"label\"].map({\"non-dementia\": 0, \"dementia\": 1})\n",
    "    df = df.dropna(subset=[\"label_num\"])\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c.startswith(\"feature_\")]\n",
    "\n",
    "    return df, feature_cols\n",
    "\n",
    "DATA_PATH_DEFAULT = \"combined_audio_features_transcripts.csv\"\n",
    "\n",
    "st.sidebar.header(\"âš™ï¸ Settings\")\n",
    "data_path = st.sidebar.text_input(\n",
    "    \"Path to combined feature dataset (.csv)\",\n",
    "    value=DATA_PATH_DEFAULT\n",
    ")\n",
    "\n",
    "try:\n",
    "    df, feature_cols = load_data(data_path)\n",
    "except Exception as e:\n",
    "    st.error(f\"Could not load data from `{data_path}`.\\n\\nError: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "st.subheader(\"ðŸ“‚ Dataset Overview\")\n",
    "st.write(f\"Rows: **{df.shape[0]}**, Columns: **{df.shape[1]}**\")\n",
    "st.dataframe(df.head())\n",
    "\n",
    "# Class distribution\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "label_pct = (label_counts / len(df) * 100).round(2)\n",
    "dist_df = pd.DataFrame({\n",
    "    \"label\": label_counts.index,\n",
    "    \"count\": label_counts.values,\n",
    "    \"percentage\": label_pct.values\n",
    "})\n",
    "\n",
    "st.markdown(\"### Class Distribution\")\n",
    "fig_dist = px.bar(\n",
    "    dist_df,\n",
    "    x=\"label\",\n",
    "    y=\"count\",\n",
    "    text=\"percentage\",\n",
    "    title=\"Dementia vs Non-Dementia Counts\",\n",
    ")\n",
    "fig_dist.update_traces(textposition=\"outside\")\n",
    "st.plotly_chart(fig_dist, use_container_width=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Train/Test split + model\n",
    "# -------------------------------\n",
    "st.markdown(\"### ðŸ”¬ Train / Test Split and Model Training\")\n",
    "\n",
    "test_size = st.sidebar.slider(\"Test Size (fraction)\", 0.1, 0.4, 0.2, 0.05)\n",
    "random_state = st.sidebar.number_input(\"Random Seed\", min_value=0, max_value=9999, value=42)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[\"label_num\"].astype(int).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    ")\n",
    "\n",
    "# Random Forest hyperparameters (you can tweak based on tuning results)\n",
    "n_estimators = st.sidebar.selectbox(\"Random Forest: n_estimators\", [100, 200, 300, 500], index=2)\n",
    "max_depth = st.sidebar.selectbox(\"Random Forest: max_depth\", [None, 5, 10, 15], index=0)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "col1, col2, col3, col4, col5 = st.columns(5)\n",
    "col1.metric(\"Accuracy\", f\"{acc:.3f}\")\n",
    "col2.metric(\"Precision\", f\"{prec:.3f}\")\n",
    "col3.metric(\"Recall\", f\"{rec:.3f}\")\n",
    "col4.metric(\"F1-Score\", f\"{f1:.3f}\")\n",
    "col5.metric(\"ROC-AUC\", f\"{auc:.3f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"True Non-Dementia\", \"True Dementia\"],\n",
    "    columns=[\"Pred Non-Dementia\", \"Pred Dementia\"]\n",
    ")\n",
    "\n",
    "st.markdown(\"### Confusion Matrix\")\n",
    "fig_cm = px.imshow(\n",
    "    cm_df,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    title=\"Confusion Matrix\"\n",
    ")\n",
    "st.plotly_chart(fig_cm, use_container_width=True)\n",
    "\n",
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "imp_df = pd.DataFrame({\"feature\": feature_cols, \"importance\": importances})\n",
    "imp_df = imp_df.sort_values(by=\"importance\", ascending=False).head(15)\n",
    "\n",
    "st.markdown(\"### Top 15 Feature Importances (Random Forest)\")\n",
    "fig_imp = px.bar(\n",
    "    imp_df,\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Most Important Audio Features\"\n",
    ")\n",
    "fig_imp.update_layout(yaxis={\"categoryorder\": \"total ascending\"})\n",
    "st.plotly_chart(fig_imp, use_container_width=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Predict on new uploaded data\n",
    "# -------------------------------\n",
    "st.markdown(\"## ðŸ”Ž Predict Dementia on New Data\")\n",
    "\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "Upload a **CSV file** that contains the same `feature_...` columns  \n",
    "(e.g., feature_1, feature_2, ..., feature_30).  \n",
    "The app will output predicted label and dementia probability for each row.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload feature CSV for prediction\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    new_df = pd.read_csv(uploaded_file)\n",
    "\n",
    "    # Check for required feature columns\n",
    "    missing = [c for c in feature_cols if c not in new_df.columns]\n",
    "    if missing:\n",
    "        st.error(f\"Uploaded file is missing these feature columns: {missing}\")\n",
    "    else:\n",
    "        X_new = new_df[feature_cols].values\n",
    "        new_proba = rf.predict_proba(X_new)[:, 1]\n",
    "        new_pred = (new_proba >= 0.5).astype(int)\n",
    "\n",
    "        new_df[\"predicted_label_num\"] = new_pred\n",
    "        new_df[\"predicted_label\"] = new_df[\"predicted_label_num\"].map(\n",
    "            {0: \"non-dementia\", 1: \"dementia\"}\n",
    "        )\n",
    "        new_df[\"dementia_probability\"] = new_proba\n",
    "\n",
    "        st.markdown(\"### ðŸ§¾ Predictions\")\n",
    "        st.dataframe(new_df)\n",
    "\n",
    "        csv_out = new_df.to_csv(index=False).encode(\"utf-8\")\n",
    "        st.download_button(\n",
    "            label=\"ðŸ“¥ Download Predictions as CSV\",\n",
    "            data=csv_out,\n",
    "            file_name=\"dementia_predictions.csv\",\n",
    "            mime=\"text/csv\"\n",
    "        )\n",
    "else:\n",
    "    st.info(\"Upload a CSV file above to run predictions on new data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
